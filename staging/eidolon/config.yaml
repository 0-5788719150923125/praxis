# Eidolon - Nose-Touch Detection Pipeline Configuration

# Model configuration
model:
  name: "facebook/deit-small-patch16-224"
  num_classes: 2
  image_size: 224

# Frame extraction settings
extraction:
  fps: 5 # Sample rate (frames per second to extract)
  quality: 95 # JPEG quality (1-100)

# Training configuration
training:
  batch_size: 32
  learning_rate: 0.0001
  epochs: 30
  early_stopping_patience: 15
  weight_decay: 0.01
  warmup_steps: 0
  train_split: 0.70
  val_split: 0.15
  test_split: 0.15
  use_class_weights: true # Balance classes if imbalanced

  # PEFT (Parameter-Efficient Fine-Tuning) configuration
  use_peft: true # Use LoRA instead of full fine-tuning
  peft:
    r: 16 # LoRA rank (higher = more parameters, 8-64 typical)
    lora_alpha: 32 # LoRA scaling factor (typically 2x rank)
    lora_dropout: 0.1 # Dropout for LoRA layers
    # Target modules: must match actual layer names in the model
    # For DeiT/ViT: ["query", "value"] or ["query", "key", "value"]
    # Run training once to see "Available linear layers" list
    target_modules: ["key", "query", "value"]
    bias: "lora_only" # Bias training strategy: "none", "all", or "lora_only"

# Inference configuration
inference:
  batch_size: 256 # Larger batch = faster inference (can go up to 512 on good GPUs)
  threshold: 0.5 # Classification threshold (lower = more detections)
  min_event_duration: 0.4 # Minimum duration in seconds (filters brief detections)
  use_gpu: true # Use GPU if available

# MLT project generation
mlt:
  marker_buffer: 2.0 # seconds before prediction to place timeline cut/marker
  output_dir: "outputs/projects"

# Paths
paths:
  videos: "videos"
  frames: "data/frames"
  labels: "data/labels.csv"
  dataset: "data/dataset"
  models: "models"
  predictions: "outputs/predictions"
  events: "outputs/events"
