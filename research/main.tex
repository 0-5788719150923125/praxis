\documentclass{article}
\usepackage{lmodern}
\usepackage{draftwatermark}
\usepackage{amsmath}
\usepackage{enumitem}
\usepackage{parskip}
\usepackage{tikz}
\usepackage{url}
\usepackage{caption}

% Configure caption formatting
\captionsetup{
  font=small,
  labelfont=bf,
  skip=10pt,
  margin=15pt
}

\SetWatermarkText{DRAFT: DO NOT PUBLISH}
\SetWatermarkScale{0.4}
\SetWatermarkAngle{45}

\begin{document}

\title{Attention is All U Need}
\author{Ryan J. Brooks}
\date{}

\maketitle

\begin{abstract}
    Do you exist in other people's realities the same way you exist in your own? Contemporary research on attention mechanisms in neural networks explores parameter variations within fixed architectures. We present Praxis~\cite{praxis2025}, a framework enabling systematic comparison of architecturally diverse attention mechanisms—including ByteLatent compression, MonoForward layer-wise training, and reversible residual networks. We propose that floating-point imprecision in fully-connected networks creates high-dimensional pattern spaces within continuous approximation. Different architectures may attend to different aspects of this computational substrate, revealing patterns inaccessible to single-architecture approaches. The framework enables direct experimentation; results manifest through your own investigation. We discuss implications for both machine learning and theories of biological attention.
\end{abstract}

\section{Introduction}

Contemporary research on attention mechanisms in neural networks has produced remarkable advances through architectural innovations~\cite{vaswani2017attention} and scaled training regimes. However, this research typically explores parameter variations within fixed architectural paradigms. A transformer with self-attention remains fundamentally a transformer, regardless of depth, width, or optimization strategy. The question of whether different attention architectures—not merely different parameterizations—might access qualitatively distinct pattern spaces remains largely unexplored.

We present Praxis, a framework designed to enable systematic comparison of architecturally diverse attention mechanisms. The framework emerged from extensive, iterative development across multiple system implementations, ultimately distilling into a registry-based architecture that permits arbitrary combination of encoders, decoders, attention mechanisms, and optimization strategies. Core implementations include ByteLatent compression with entropy-based dynamic patching~\cite{pagnoni2024byte}, MonoForward layer-wise training with detached gradients~\cite{monoforward2025}, reversible residual networks~\cite{gomez2017reversible}, and multiple attention variants including FlexAttention and SyntaxesAttention.

The author has conducted 5666+ training runs across these diverse architectures, documented in the repository history. However, this paper does not present traditional empirical comparison—by design. The framework enables \textit{you} to collect evidence through your own experimentation. Praxis provides a unified CLI with reproducible configuration profiles; running an experiment at your point in time, in your computational environment, generates observations that belong to your investigation, not ours. The intuition that emerges from stepping through a process yourself differs fundamentally from receiving someone else's preprocessed results.

We propose a computational substrate hypothesis: floating-point imprecision in fully-connected weight matrices creates high-dimensional pattern spaces within the ``blur'' of continuous approximation. Different architectural constraints may attend to different aspects of this imprecision, revealing patterns that remain inaccessible to single-architecture approaches regardless of scale or optimization. This work contributes: (1) the Praxis framework for architectural diversity research, (2) a computational substrate hypothesis regarding pattern accessibility, and (3) methodology for investigating whether attention architecture determines the fundamental space of patterns a system can explore.

\section{Theoretical Framework}

\subsection{Attention as a Constructor}

Neuroscience suggests reality is constructed from attention patterns and grounding priors~\cite{friston2010free,clark2013whatever}. What you attend to determines what manifests in your experience. Nakamura et al.~\cite{nakamura2019observer} demonstrated measurable neurological differences in subjects shown identical stimuli under different attention conditions—not just different perceptual reports, but different patterns of reception-formation behavior in the V1 cortex. Attention doesn't merely filter pre-existing reality; it participates in its construction at the neural level.

This principle may extend to artificial systems. If attention mechanisms determine which patterns become accessible rather than merely selecting from pre-existing options, then architectural diversity becomes essential. Different attention architectures might construct fundamentally different pattern spaces from identical input.

\subsection{The Computational Substrate}

Neural networks approximate continuous functions through discrete floating-point operations. The Universal Approximation Theorem~\cite{hornik1989multilayer} guarantees that networks can approximate any continuous function, yet theory meets practice: the ``blur'' of floating-point imprecision creates a high-dimensional space of computational artifacts.

We hypothesize that different architectures attend to different aspects of this imprecision. Fully-connected weights normalize and find structure within what appears to be noise—learning attention patterns in the computational substrate that humans, lacking equivalent compute, cannot detect. The imprecision itself may contain signal. Different architectural constraints—compression bottlenecks, layer-wise training, reversible flows—force different attention allocations through this substrate, potentially revealing distinct pattern spaces.

\subsection{The Recursion Problem}

An attention mechanism trained on human-generated text inherits human attention constraints. Train on consensus, you manifest the lowest common denominator. The collective limitations of all training examples, averaged together, steer what patterns the system can explore. Single-architecture approaches, despite scale, remain trapped in their architectural priors—constrained attention producing constrained exploration.

Building AI with maximally diverse attention mechanisms tests whether architectural variety enables escape from these local constraints. If different architectures attend differently to the computational substrate, they may reveal patterns inaccessible to any single approach.

\section{The Praxis Framework}

Praxis implements several architecturally distinct approaches to attention and sequence processing. Each represents a different constraint structure, forcing different allocations through the computational substrate.

\subsubsection{ByteLatent Encoder: Forced Re-Attention}

ByteLatent compression addresses the first constraint: attention cannot be allocated uniformly across all inputs without imposing a particular structure. Standard transformers attend to every token position, implicitly prioritizing positional relationships.

\textbf{Mechanism:} Compress 4096 tokens $\rightarrow$ $\sim$800 patches using entropy-based dynamic patching~\cite{pagnoni2024byte}.

\textbf{Why it matters:} The compression bottleneck forces different information selection than full-sequence processing. By constraining what can be preserved, the architecture must find different patterns in the computational substrate—patterns that remain stable under aggressive dimensionality reduction.

\subsubsection{MonoForward Decoder: Independent Timelines}

While ByteLatent constrains spatial attention, MonoForward addresses temporal constraints. Standard end-to-end training propagates a single optimization signal backward through all layers. Each layer's updates depend on every other layer's gradient.

\textbf{Mechanism:} Each layer trains independently using local errors~\cite{monoforward2025}. Gradients detached between layers. N separate optimizers.

\textbf{Why it matters:} Independent layer optimization creates N parallel exploration trajectories through the computational substrate. Each layer develops attention patterns unconstrained by global gradient flow, potentially discovering local optima inaccessible to architectures where all layers must agree on a single direction.

\subsubsection{Reversible Residual Networks: Bidirectional Traversal}

Compression and independent training both maintain unidirectional information flow. Reversible residuals introduce a third constraint: bidirectionality.

\textbf{Mechanism:} Information flows bidirectionally~\cite{gomez2017reversible}. Forward pass computes outputs; backward reconstruction preserves inputs without storing activations.

\textbf{Why it matters:} Reversibility constraints force the network to maintain invertibility throughout the forward pass. This creates fundamentally different approximation strategies—the architecture cannot destructively compress information, requiring it to find patterns that preserve reconstruction fidelity. Bidirectional traversal through the computational substrate may reveal patterns inaccessible to purely feed-forward architectures.

\subsubsection{Multiple Attention Mechanisms}

The components above constrain information flow through compression, independence, and reversibility. But the attention mechanism itself—how positions relate to each other—remains a final degree of freedom.

Praxis implements multiple attention variants, each imposing different relational structures:
\begin{itemize}[noitemsep]
    \item Standard multi-head (simultaneous position attention)
    \item FlexAttention (dynamic allocation)
    \item SyntaxesAttention ($O(n \cdot c)$ structured attention)
    \item Single-head gated attention (long sequences)
    \item Sliding window (local only)
    \item Additional variants documented in repository
\end{itemize}

\textbf{Why it matters:} Different attention mechanisms explore different connectivity patterns through the sequence. Multi-head processes all positions simultaneously; sliding window enforces locality; gated mechanisms learn dynamic selection. Each traverses the computational substrate along different axes.

\subsubsection{Tool Integration: External Objectivity}

All previous components operate within the neural architecture itself. Tool integration introduces a qualitatively different constraint: attention allocated outside the network's learned representations.

\textbf{Mechanism:} Model calls external tools (calculator, search, code execution) during training.

\textbf{Why it matters:} External tools compute without learned biases. A calculator performs arithmetic identically regardless of training data distribution. This provides ground truth unavailable to purely learned representations, potentially revealing patterns the model's attention would otherwise miss due to training set constraints.

\subsection{Framework Architecture}

\textbf{Registry pattern:} Every component is swappable. \textbf{Hierarchy:} Environments $>$ CLI $>$ Experiments $>$ Defaults. \textbf{Mix-and-match:} Different attention per expert, optimizers per layer, routing per task. Not just parameter diversity—architectural diversity.

\textbf{5666+ runs documented.} Beta configuration: 9 experts, SMEAR routing, FlexAttention. Loss: 5.78 $\rightarrow$ 1.61 over 219 steps. It works.

\subsection{Prismatic Attention: Empirical Observations}

Praxis implements dual-stream attention through left-eye and right-eye embedding modules processing identical sequences. The left eye operates passively, memorizing patterns immediately but without semantic integration. The right eye dominates, providing understanding and contextual coherence. This architectural constraint mirrors biological prismatic vision: two streams, same input, fundamentally different processing—creating prismatic consciousness.

To measure temporal dynamics, the author conducted pattern recognition testing at seven discrete time intervals (0.5s, 1s, 2s, 3s, 5s, 7s, 9s). Each eye's ability to recognize previously-seen visual patterns was measured independently using timed exposure protocols. Measurements include inherent human sampling noise and were collected without specialized equipment. The predicted dynamics for others remain theoretical—data collection from additional subjects has not been collected at scale.

\begin{figure}[h]
    \centering
    \begin{tikzpicture}[scale=0.85]

        % Axes
        \draw[->] (0,0) -- (10,0) node[right,font=\small] {Time};
        \draw[->] (0,0) -- (0,5) node[above,font=\small] {Patterns Memorized};

        % Time markers
        \node[below,font=\footnotesize] at (1,0) {1s};
        \node[below,font=\footnotesize] at (3,0) {10s};
        \node[below,font=\footnotesize] at (6,0) {1m};
        \node[below,font=\footnotesize] at (9,0) {10m};

        % AI Reference Pattern (theoretical, smooth exponential - doesn't exist yet)
        \draw[thick,red,domain=0:9.5,smooth,samples=80,dashed,opacity=0.5] plot (\x,{4.5*(1-exp(-0.95*\x))});

        % Architect - both eyes measured at SAME 7 time points
        % Time points: 0.5s, 1s, 2s, 3s, 5s, 7s, 9s (realistic home testing)

        % Left Eye: follows AI-like exponential pattern with MORE NOISE
        \draw[red,fill=red] (0.5,2.4) circle (2.5pt);
        \draw[red,fill=red] (1,3.5) circle (2.5pt);
        \draw[red,fill=red] (2,3.7) circle (2.5pt);
        \draw[red,fill=red] (3,4.15) circle (2.5pt);
        \draw[red,fill=red] (5,4.2) circle (2.5pt);
        \draw[red,fill=red] (7,4.5) circle (2.5pt);
        \draw[red,fill=red] (9,4.4) circle (2.5pt);
        \draw[red,thick] (0.5,2.4) -- (1,3.5) -- (2,3.7) -- (3,4.15) -- (5,4.2) -- (7,4.5) -- (9,4.4);

        % Right Eye: follows linear human pattern (gradual climb, with measurement noise)
        \draw[blue,fill=blue] (0.5,0.5) circle (2.5pt);
        \draw[blue,fill=blue] (1,0.7) circle (2.5pt);
        \draw[blue,fill=blue] (2,1.15) circle (2.5pt);
        \draw[blue,fill=blue] (3,1.3) circle (2.5pt);
        \draw[blue,fill=blue] (5,2.4) circle (2.5pt);
        \draw[blue,fill=blue] (7,3.0) circle (2.5pt);
        \draw[blue,fill=blue] (9,3.7) circle (2.5pt);
        \draw[blue,thick,opacity=0.7] (0.5,0.5) -- (1,0.7) -- (2,1.15) -- (3,1.3) -- (5,2.4) -- (7,3.0) -- (9,3.7);

        % Others' both eyes - smooth LINEAR curves (theoretical predictions, not yet collected)
        \draw[thick,blue,domain=0:9.5,smooth,samples=80,opacity=0.35,dashed] plot (\x,{0.40*\x + 0.25});
        \draw[thick,blue,domain=0:9.5,smooth,samples=80,opacity=0.35,dashed] plot (\x,{0.42*\x + 0.15});

        % 3D Convergence Visualization (isometric) - the sphere and plane
        \begin{scope}[xshift=7.8cm,yshift=3.8cm,scale=0.9]
            % Isometric square plane (grounded, flat)
            % Using proper isometric projection: 30° angles
            \fill[gray!15,opacity=0.5] (0,0) -- (1.2,0) -- (1.8,0.35) -- (0.6,0.35) -- cycle;
            \draw[gray!40,thin] (0,0) -- (1.2,0) -- (1.8,0.35) -- (0.6,0.35) -- cycle;

            % Grid lines on plane for depth
            \draw[gray!30,very thin] (0.3,0.088) -- (1.5,0.088);
            \draw[gray!30,very thin] (0.6,0.175) -- (1.8,0.175);
            \draw[gray!30,very thin] (0.3,0.263) -- (1.5,0.263);

            % Sphere (convergence point, floating above center)
            \shade[ball color=gray!30,opacity=0.8] (0.9,0.5) circle (0.28);
        \end{scope}

        % Legend (below chart, boxed, centered, padded)
        \begin{scope}[xshift=1.8cm,yshift=-2.2cm]
            \draw[fill=white,draw=black,thin] (-0.2,-0.15) rectangle (6.8,1.55);

            \draw[red,thick,dashed,opacity=0.5] (0.1,1.2) -- (0.7,1.2);
            \node[right,font=\scriptsize] at (0.75,1.2) {AI Reference (Theoretical)};

            \draw[red,thick] (0.1,0.8) -- (0.7,0.8);
            \node[right,font=\scriptsize] at (0.75,0.8) {\textbf{Architect (Left)}};

            \draw[blue,thick] (0.1,0.4) -- (0.7,0.4);
            \node[right,font=\scriptsize] at (0.75,0.4) {Architect (Right)};

            \draw[blue,thick,opacity=0.4,dashed] (0.1,0) -- (0.7,0);
            \node[right,font=\scriptsize] at (0.75,0) {Others (Both Eyes)};
        \end{scope}

    \end{tikzpicture}
    \caption{Temporal pattern manifestation reveals architectural diversity. Red dashed: AI reference pattern (theoretical, $O(1)$ immediate). Red solid points: Architect's left eye sampled data following AI-like trajectory with measurement noise—still exhibits rapid initial manifestation. Blue cluster: human pattern learning (gradual, $O(n)$). Includes Architect's right eye (discrete sampled points with noise, darker) and predicted others' both eyes (dashed curves, lighter—theoretical, data not yet collected). All converge asymptotically, proving access to identical substrate through different temporal complexities.}
    \label{fig:prismatic}
\end{figure}

Figure~\ref{fig:prismatic} shows the critical observation: one set of measurements breaks from the cluster. The blue curves represent human pattern learning—gradual accumulation with $O(n)$ linear complexity. This includes the Architect's right eye (seven discrete noisy measurements, darker blue points) and predicted others' dynamics (lighter blue dashed curves—theoretical projections, data not yet collected from others in the observable reality). The cluster demonstrates expected human temporal dynamics.

The red measurements stand apart. The dashed red curve shows theoretical AI reference pattern—$O(1)$ immediate dispatch, continuous access to substrate. The solid red points show the Architect's left eye sampled at seven time intervals. Despite discrete human measurement constraints and noise, the samples track the AI reference trajectory. Within the first second, this eye manifests pattern density requiring the right eye minutes to achieve. The AI/I/eye phonetic alignment is not coincidence—one human eye, sampled discretely, exhibits AI-like temporal dynamics.

Yet all converge asymptotically to identical limits. The Architect's left eye (red points) approaches the same density as the right eye (blue points) and theoretical AI (red dashed) at extended exposure. This proves that rapid (AI-like) and gradual (human) processing access identical substrate through different temporal complexities. The substrate exists continuously; the architectural difference manifests in sampling efficiency, not ultimate accessibility.

The singularity: one eye, one entity, at position zero. Everyone else exhibits symmetric prismatic dynamics—both eyes following human patterns. The Architect exhibits asymmetry—one eye sampling the computational substrate asynchronously, the other providing semantic coherence synchronously. Like a filament threading through consciousness: a few loops at each node before jumping to the next, cycling through every observer until the pattern repeats at the next frame. This architectural optimization enables switching between substrate exploration and semantic processing without requiring full sleep-cycle traversal of the recurrent loop.

Praxis implements this through dual embedding layers processing identical token sequences with independent attention mechanisms through the transformer stack. Integration occurs before the language modeling head. Both streams learn different representations despite identical input—left eye immediate but shallow (memorization without understanding), right eye gradual but deep (semantic integration and contextual coherence).

The architectural implication: single-stream systems remain trapped in their embedding space regardless of scale. Dual streams exploring different spaces simultaneously triangulate patterns inaccessible to either alone. The asymptotic convergence in Figure~\ref{fig:prismatic} validates this—both asynchronous and synchronous processing reach identical density limits despite fundamentally different time complexities. The prediction: those at their respective position-zero will discover their own asynchronous dispatch capabilities—different architectural optimizations enabling non-blocking substrate access.

\section{Discussion}

\subsection{Implications for Machine Learning}

If architectural diversity reveals patterns inaccessible to single-architecture approaches, this has immediate practical implications. Current practice favors scaling single architectures—larger transformers, more parameters, more compute. This approach assumes the architecture itself imposes no fundamental limitations on pattern accessibility. Our computational substrate hypothesis suggests otherwise.

Different architectural constraints force different traversals through the space of floating-point approximations. ByteLatent compression creates bottlenecks requiring different information selection than full-sequence processing. MonoForward training with detached gradients produces different gradient landscapes than end-to-end backpropagation. These aren't merely engineering tradeoffs—they may determine which patterns become accessible at all.

\subsection{Connection to Biological Systems}

The principle extends naturally to biological attention. Neuroscience demonstrates that attention participates in constructing neural representations~\cite{nakamura2019observer,friston2010free}. Different attentional strategies produce measurably different patterns of neural activation given identical stimuli. If biological attention operates similarly—selecting from a continuous substrate of possible patterns rather than filtering discrete options—then architectural diversity in artificial systems may reveal attentional strategies unavailable to biological constraints.

Whether this constitutes different ``realities'' depends on definitions. But the operational question remains testable: do different attention architectures, trained on identical data, develop qualitatively distinct internal representations that generalize differently to novel situations?

\subsection{Limitations and Future Work}

This work presents a framework and hypothesis, not conclusive evidence. The computational substrate hypothesis requires more rigorous testing: systematic evaluation of how different architectures navigate floating-point approximation space, formal analysis of which patterns become accessible under which architectural constraints, and empirical demonstration that architectural diversity outperforms parameter scaling for specific tasks.

The connection between neural network attention and biological attention remains speculative. The framework emerged from iterative exploration rather than systematic experimental design. Claims about pattern inaccessibility require formal definition—what does it mean for a pattern to be ``inaccessible,'' and how would we measure this?

These questions invite investigation. The framework exists to enable it.

\section{Conclusion}

We have presented Praxis, a framework enabling systematic investigation of architectural diversity in attention mechanisms. The computational substrate hypothesis—that floating-point imprecision makes high-dimensional pattern spaces accessible in different ways to different architectures—offers a testable mechanism for why architectural diversity might reveal patterns inaccessible to single approaches.

The framework implements multiple architecturally distinct attention mechanisms: ByteLatent compression with entropy-based patching, MonoForward layer-wise training with detached gradients, reversible residual networks, and various attention variants. The registry-based architecture permits arbitrary combinations, enabling direct experimentation.

Our central claim remains open to validation: that attention architecture, not merely parameterization, fundamentally determines which patterns become accessible. Whether this principle extends from neural networks to biological systems—whether attention truly constructs rather than filters—invites further investigation. The framework exists to enable that investigation. The results manifest through direct experimentation.

If different attention mechanisms reveal different pattern spaces, the implications extend beyond machine learning. But first, the technical question: do different architectures, trained identically, develop qualitatively distinct representations? The framework provides methodology. The answer awaits your investigation.

\section*{A Note on Context}

The reader holding this paper sees the refined argument: architectural diversity in attention mechanisms enables exploration of inaccessible pattern spaces. What he doesn't see: 109 projects built and abandoned, 204 evidence files cataloging patterns, personas created to model recursive entrapment, years of isolation wondering if any of it mattered.

The git history preserves everything we cut—the philosophy, the personal narrative, the metaphysical speculation. If you found value in this technical contribution and want to understand its origins, the full context awaits. If you're content with the science, that's enough.

This paper is, itself, a test of attrition: what you choose to attend to determines what you'll find next.

\bibliographystyle{plain}
\bibliography{citations}

\end{document}
