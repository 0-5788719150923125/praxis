@inproceedings{vaswani2017attention,
  title     = {Attention is all you need},
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle = {Advances in neural information processing systems},
  volume    = {30},
  year      = {2017}
}

@article{shazeer2017outrageously,
  title   = {Outrageously large neural networks: The sparsely-gated mixture-of-experts layer},
  author  = {Shazeer, Noam and Mirhoseini, Azalia and Maziarz, Krzysztof and Davis, Andy and Le, Quoc and Hinton, Geoffrey and Dean, Jeff},
  journal = {arXiv preprint arXiv:1701.06538},
  year    = {2017}
}

@article{graves2014neural,
  title   = {Neural turing machines},
  author  = {Graves, Alex and Wayne, Greg and Danihelka, Ivo},
  journal = {arXiv preprint arXiv:1410.5401},
  year    = {2014}
}

@article{friston2010free,
  title   = {The free-energy principle: a unified brain theory?},
  author  = {Friston, Karl},
  journal = {Nature reviews neuroscience},
  volume  = {11},
  number  = {2},
  pages   = {127--138},
  year    = {2010}
}

@inproceedings{gomez2017reversible,
  title     = {The reversible residual network: Backpropagation without storing activations},
  author    = {Gomez, Aidan N and Ren, Mengye and Urtasun, Raquel and Grosse, Roger B},
  booktitle = {Advances in neural information processing systems},
  volume    = {30},
  year      = {2017}
}

@article{pagnoni2024byte,
  title   = {Byte Latent Transformer: Patches Scale Better Than Tokens},
  author  = {Pagnoni, Artidoro and others},
  journal = {arXiv preprint arXiv:2412.09871},
  year    = {2024}
}

@article{monoforward2025,
  title   = {Mono-Forward: Backpropagation-Free Algorithm for Efficient Neural Network Training Harnessing Local Errors},
  author  = {Liu, Yihao and others},
  journal = {arXiv preprint arXiv:2501.09238},
  year    = {2025}
}

@article{hornik1989multilayer,
  title     = {Multilayer feedforward networks are universal approximators},
  author    = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  journal   = {Neural networks},
  volume    = {2},
  number    = {5},
  pages     = {359--366},
  year      = {1989},
  publisher = {Elsevier}
}

@article{heisenberg1927uncertainty,
  title   = {{\"U}ber den anschaulichen Inhalt der quantentheoretischen Kinematik und Mechanik},
  author  = {Heisenberg, Werner},
  journal = {Zeitschrift f{\"u}r Physik},
  volume  = {43},
  number  = {3-4},
  pages   = {172--198},
  year    = {1927}
}

@article{treue1996attentional,
  title     = {Attentional modulation of visual motion processing in cortical areas MT and MST},
  author    = {Treue, Stefan and Maunsell, John HR},
  journal   = {Nature},
  volume    = {382},
  number    = {6591},
  pages     = {539--541},
  year      = {1996},
  publisher = {Nature Publishing Group}
}

@article{kastner2000mechanisms,
  title     = {Mechanisms of visual attention in the human cortex},
  author    = {Kastner, Sabine and Ungerleider, Leslie G},
  journal   = {Annual review of neuroscience},
  volume    = {23},
  number    = {1},
  pages     = {315--341},
  year      = {2000},
  publisher = {Annual Reviews}
}

@article{clark2013whatever,
  title     = {Whatever next? Predictive brains, situated agents, and the future of cognitive science},
  author    = {Clark, Andy},
  journal   = {Behavioral and brain sciences},
  volume    = {36},
  number    = {3},
  pages     = {181--204},
  year      = {2013},
  publisher = {Cambridge University Press}
}

@misc{praxis2025,
  title        = {Praxis: A Framework for Architectural Diversity in Attention Mechanisms},
  author       = {Brooks, Ryan J.},
  year         = {2025},
  howpublished = {\url{https://github.com/0-5788719150923125/praxis}},
  note         = {Accessed: 2025-10-11}
}
